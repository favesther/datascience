{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and prepare the data (20pt)\n",
    "As the first step, explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2pt) Load the data. How many responses and variables do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs=pd.read_csv(\"data/wvs.csv.bz2\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90350, 328)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 90350 responses and 328 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3pt) Create a summary table over all responses for V204: \n",
    "is abortion justifiable. How many non-missing responses (i.e. positive answers) do you find? Describe the the opinion about the abortion among the global pool of respondents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v204=wvs.V204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90350.000000\n",
       "mean         2.946386\n",
       "std          2.964040\n",
       "min         -5.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          5.000000\n",
       "max         10.000000\n",
       "Name: V204, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v204.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85742"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The total positive answer\n",
    "v204[v204>0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to know how many people made which choice, so I will output a dataframe to summarize the results. Also, I will output which choice is the most popular and which least people chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most people (40227) chose 1\n",
      "least people (23) chose -5\n"
     ]
    }
   ],
   "source": [
    "max=0\n",
    "max_choice=0\n",
    "min_choice=0\n",
    "min=85742\n",
    "n=0\n",
    "values=v204.unique()\n",
    "#create a dictionary to record every choice and the sum of the people who made this choice.\n",
    "dic={'choice':[],'count':[]}\n",
    "for i in values:\n",
    "    dic['choice'].append(i)\n",
    "    n=v204[v204==i].count()\n",
    "    dic['count'].append(n)\n",
    "    if n>max: \n",
    "        max=n\n",
    "        max_choice=i \n",
    "    if n<min: \n",
    "        min=n\n",
    "        min_choice=i\n",
    "print (\"most people (\", end=\"\")\n",
    "print(max,end=\"\")\n",
    "print (\") chose\", end=\" \")\n",
    "print(max_choice)\n",
    "\n",
    "print(\"least people (\", end=\"\")\n",
    "print(min,end=\"\")\n",
    "print (\") chose\", end=\" \")\n",
    "print (min_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choice</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>40227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>9580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>7896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>6294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>4067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>3493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>3397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-4</td>\n",
       "      <td>1523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    choice  count\n",
       "0        1  40227\n",
       "1        5   9580\n",
       "2       -2   1045\n",
       "3        4   4497\n",
       "4        6   4395\n",
       "5        2   7896\n",
       "6        3   6294\n",
       "7       10   4067\n",
       "8        7   3493\n",
       "9        8   3397\n",
       "10       9   1896\n",
       "11      -1   2017\n",
       "12      -4   1523\n",
       "13      -5     23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary=pd.DataFrame(dic,columns=['choice','count'])\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 85742 positive answers. The average score of the level of the issue that whether abortion is justifiable is approaximately 3 - more of not justifiable. Most people (40227) chose 1, which means most people contended that abortion is never justifiable. Least people (23) chose -5 - the most vague answer in the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (4pt) Now remove missings. We do it in two ways:\n",
    "(a) remove everything that are not positive integers for V204 and V2 (country).  \n",
    "(b) for all other variables, remove the missings in the sense of missing value on computer. You may\n",
    "leave negative answers in the data, otherwise I am afraid your sample size collapses.\n",
    "What is the final number of observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#copy the original dataset\n",
    "wvs_original=wvs.copy()\n",
    "#drop missing values\n",
    "wvs=wvs.dropna(axis=0)\n",
    "wvs=wvs[(wvs.V204>0) & (wvs.V2>0) ]\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (2pt) In order to simplify the analysis below, create a new binary variable abortion as\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace values under conditions\n",
    "wvs['V204'].mask(wvs['V204']<=3,0,inplace=True)\n",
    "wvs['V204'].mask(wvs['V204']>3,1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test it\n",
    "wvs.V204.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5pt) Compute (pearson) correlation table between abortion and all other variables in the data.\n",
    "There are many of these!\n",
    "Present these variables in descending order according to the absolute value of the correlation.\n",
    "Take a look at a few variables that have strong correlation with abortion. What do these represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform pandas Series to numpy array\n",
    "a=wvs.V204.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict={'variable':[],'correlation':[]}\n",
    "for column in wvs:\n",
    "    dict['variable'].append(column)\n",
    "    b=wvs[column].to_numpy()\n",
    "    #in case there is inf or nan\n",
    "    b= np.nan_to_num(b)\n",
    "    p=stats.pearsonr(a,b)\n",
    "    dict['correlation'].append(p[0]) #only show the first number of pearson correlation\n",
    "pearson=pd.DataFrame(dict,columns=['variable','correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>V204</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>V205</td>\n",
       "      <td>0.548653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>V203</td>\n",
       "      <td>0.485419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>V206</td>\n",
       "      <td>0.446394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>V207</td>\n",
       "      <td>0.418271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>V138</td>\n",
       "      <td>-0.142894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>V255</td>\n",
       "      <td>-0.149844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>V223</td>\n",
       "      <td>-0.165924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>V252</td>\n",
       "      <td>-0.191483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>V152</td>\n",
       "      <td>-0.315280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    variable  correlation\n",
       "228     V204     1.000000\n",
       "229     V205     0.548653\n",
       "226     V203     0.485419\n",
       "230     V206     0.446394\n",
       "231     V207     0.418271\n",
       "..       ...          ...\n",
       "152     V138    -0.142894\n",
       "298     V255    -0.149844\n",
       "260     V223    -0.165924\n",
       "296     V252    -0.191483\n",
       "165     V152    -0.315280\n",
       "\n",
       "[328 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort the dataframe in a descending order\n",
    "pearson.sort_values(by=['correlation'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4pt) convert country code V2 into dummies.   \n",
    "* First rename V2 to country.  \n",
    "* Afterwards, remove country variable from the data. How many rows/columns do you have now?  \n",
    "* How many country dummies does the data contain?  \n",
    "* Note that get_dummies creates a dummy for every category, so you have to remove one of these\n",
    "dummies in order to avoid perfect multicollinearity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs=wvs.rename(columns={\"V2\":\"country\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no country column in the wvs2. I have 386 columns now, 58 more than the original. So there are 59 country dummies the data contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs2 = pd.get_dummies(wvs, columns = ['country'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 384)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Cross-Validation (40pt)\n",
    "Now it's time to write your own code that does k-fold CV. I recommend to go the following path:\n",
    "(3pt) Make it as a function that takes k, the (unfiittted) model, features X and the target y as arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " (10pt) Next, one should randomly shuffle the data. However, it is easier to generate a list of indices, and shuffle those randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(25pt) Loop the following k times  \n",
    "(a) Select every k-th of your indices for validation data  \n",
    "(b) For training data, select all indices, except those that went into validation data. Hint: check\n",
    "out set operations  \n",
    "(c) Separate the data X and the target y into training/validation parts.  \n",
    "(d) Fit the model on training data  \n",
    "(e) Predict outcome on validation data  \n",
    "(f) Compute the resulting statistic (you may compute more than one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2pt) finally, return mean of the statistics.\n",
    "Note: This is my suggested path but you may follow another one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(k,model,X, y, data):\n",
    "    accuracy_scores=[]\n",
    "    f_scores=[]\n",
    "    precision_scores=[]\n",
    "    recall_scores=[]\n",
    "    a=np.random.choice(len(data),len(data),replace=False)\n",
    "    for i in range (1,k): #loop k times\n",
    "        # For training data, select all indices, except those that went into validation data.\n",
    "        train_index=a[a%k != i] #Select every k-th of your indices for validation data\n",
    "        valid_index=a[a%k == i]\n",
    "        #Separate the data X and the target y into training/validation parts.\n",
    "        X_train=X.iloc[train_index]\n",
    "        X_valid=X.iloc[valid_index]\n",
    "        y_train=y.iloc[train_index]\n",
    "        y_valid=y.iloc[valid_index]\n",
    "        model.fit(X_train, y_train) # Fit the model on training data\n",
    "        y1=model.predict(X_valid) # Predict outcome on validation data\n",
    "        accuracy_scores.append(accuracy_score(y_valid, y1)) #score predict y and validation y\n",
    "        f_scores.append(f1_score(y_valid,y1))\n",
    "        precision_scores.append(precision_score(y_valid,y1))\n",
    "        recall_scores.append(recall_score(y_valid, y1))\n",
    "    \n",
    "    dict={'accuracy score':accuracy_scores,'false 1 score':f_scores,\n",
    "          'precision score': precision_scores,'recall score': recall_scores}\n",
    "    scores=pd.DataFrame(dict,columns=['accuracy score','false 1 score','precision score','recall score'])\n",
    "    print (scores)\n",
    "    print ('mean accuracy score:',np.mean(accuracy_scores),'\\nmean false 1 score:',np.mean(f_scores),'\\nmean precision score:', np.mean(precision_scores),'\\nmean recall score:', np.mean(recall_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best model (40)\n",
    "\n",
    "## k-NN (13pt)\n",
    "First, use k-NN and experiment with a few different k-s.\n",
    "1. (2pt) Separate your training data into X (features), and y (target). Target will be the abortion\n",
    "variable, X are all the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_sample=wvs.sample(10000)\n",
    "y=wvs_sample.V204\n",
    "X=wvs_sample.drop('V204',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (2pt) pick a k and set up the k-NN model. Use your freshly-minted CV routine to cross-validate\n",
    "accuracy and F-score of your k-NN model.\n",
    "3. (5pt) Try a few different k-NN models (pick different k, choose to normalize/not-to-normalize your\n",
    "features).\n",
    "4. (4pt) Present the results from your best k-NN model. Note: as you are using two metrics here, you\n",
    "may end up with different models performing better according to different measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy score  false 1 score  precision score  recall score\n",
      "0          0.7230       0.622101         0.619565      0.624658\n",
      "1          0.7390       0.648721         0.653117      0.644385\n",
      "2          0.7190       0.624332         0.600257      0.650418\n",
      "3          0.7395       0.649630         0.632199      0.668050\n",
      "mean accuracy score: 0.730125 \n",
      "mean false 1 score: 0.6361960083216345 \n",
      "mean precision score: 0.6262844427112344 \n",
      "mean recall score: 0.6468775452034284\n"
     ]
    }
   ],
   "source": [
    "cv(5,KNeighborsClassifier(n_neighbors=1),X,y,wvs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy score  false 1 score  precision score  recall score\n",
      "0          0.7645       0.663331         0.693572      0.635616\n",
      "1          0.7820       0.687679         0.740741      0.641711\n",
      "2          0.7600       0.664336         0.667135      0.661560\n",
      "3          0.7670       0.668563         0.688141      0.650069\n",
      "mean accuracy score: 0.7683749999999999 \n",
      "mean false 1 score: 0.6709772495628812 \n",
      "mean precision score: 0.6973971562083636 \n",
      "mean recall score: 0.6472391782938246\n"
     ]
    }
   ],
   "source": [
    "cv(5,KNeighborsClassifier(n_neighbors=5),X,y,wvs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy score  false 1 score  precision score  recall score\n",
      "0          0.7685       0.641918         0.737123      0.568493\n",
      "1          0.7800       0.657321         0.787313      0.564171\n",
      "2          0.7680       0.643625         0.717466      0.583565\n",
      "3          0.7655       0.641711         0.716724      0.580913\n",
      "mean accuracy score: 0.7705 \n",
      "mean false 1 score: 0.6461438285853078 \n",
      "mean precision score: 0.7396563233687496 \n",
      "mean recall score: 0.5742856490900379\n"
     ]
    }
   ],
   "source": [
    "cv(5,KNeighborsClassifier(n_neighbors=10),X,y,wvs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy score  false 1 score  precision score  recall score\n",
      "0          0.7645       0.641825         0.721368      0.578082\n",
      "1          0.7605       0.635187         0.738053      0.557487\n",
      "2          0.7575       0.631739         0.694491      0.579387\n",
      "3          0.7535       0.623951         0.695578      0.565698\n",
      "mean accuracy score: 0.7589999999999999 \n",
      "mean false 1 score: 0.6331754183117437 \n",
      "mean precision score: 0.7123724170088053 \n",
      "mean recall score: 0.570163621996985\n"
     ]
    }
   ],
   "source": [
    "cv(5,KNeighborsClassifier(n_neighbors=20),X,y,wvs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy score  false 1 score  precision score  recall score\n",
      "0          0.7645       0.663331         0.693572      0.635616\n",
      "1          0.7820       0.687679         0.740741      0.641711\n",
      "2          0.7600       0.664336         0.667135      0.661560\n",
      "3          0.7670       0.668563         0.688141      0.650069\n",
      "mean accuracy score: 0.7683749999999999 \n",
      "mean false 1 score: 0.6709772495628812 \n",
      "mean precision score: 0.6973971562083636 \n",
      "mean recall score: 0.6472391782938246\n"
     ]
    }
   ],
   "source": [
    "mNN = KNeighborsClassifier(n_neighbors=5).fit(preprocessing.normalize(X), y)\n",
    "cv(5,mNN,X,y,wvs_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (4pt) Present the results from your best k-NN model. Note: as you are using two metrics here, you\n",
    "may end up with different models performing better according to different measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy score  false 1 score  precision score  recall score\n",
      "0          0.7685       0.641918         0.737123      0.568493\n",
      "1          0.7800       0.657321         0.787313      0.564171\n",
      "2          0.7680       0.643625         0.717466      0.583565\n",
      "3          0.7650       0.641221         0.715503      0.580913\n",
      "mean accuracy score: 0.770375 \n",
      "mean false 1 score: 0.6460213646101273 \n",
      "mean precision score: 0.7393510748383033 \n",
      "mean recall score: 0.5742856490900379\n"
     ]
    }
   ],
   "source": [
    "cv(5,KNeighborsClassifier(n_neighbors=10),X,y,wvs_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy score  false 1 score  precision score  recall score\n",
      "0          0.7645       0.663331         0.693572      0.635616\n",
      "1          0.7820       0.687679         0.740741      0.641711\n",
      "2          0.7600       0.664336         0.667135      0.661560\n",
      "3          0.7670       0.668563         0.688141      0.650069\n",
      "mean accuracy score: 0.7683749999999999 \n",
      "mean false 1 score: 0.6709772495628812 \n",
      "mean precision score: 0.6973971562083636 \n",
      "mean recall score: 0.6472391782938246\n"
     ]
    }
   ],
   "source": [
    "cv(5,KNeighborsClassifier(n_neighbors=5),X,y,wvs_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (9pt)\n",
    "1. Now repeat the process above with logistic regression. As we have a myriad of features anyway, we\n",
    "are not going to do any feature engineering. Just a plain logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy score  false 1 score  precision score  recall score\n",
      "0          0.8320       0.760684         0.792285      0.731507\n",
      "1          0.8375       0.769993         0.818045      0.727273\n",
      "2          0.8140       0.736917         0.748563      0.725627\n",
      "3          0.7970       0.706223         0.740516      0.674965\n",
      "mean accuracy score: 0.820125 \n",
      "mean false 1 score: 0.743454024438277 \n",
      "mean precision score: 0.7748522827184431 \n",
      "mean recall score: 0.7148429348470648\n"
     ]
    }
   ],
   "source": [
    "cv(5,LogisticRegression(solver='liblinear', random_state=0),X,y,wvs_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (15pt)\n",
    "Now repeat the process with support vector machines while choosing between a few different kernels and\n",
    "kernel options, such as degree for polynomial kernels.\n",
    "Hint: I have mixed experience with sklearn version of SVM. I recommend to limit the number of\n",
    "iterations, initially maybe to just 1000, in order to ensure your model actually terminates.\n",
    "1. (14pt) pick a kernel and repeat the process above.\n",
    "Note that some kernels are slower than others, so be careful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Zhu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Zhu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Zhu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy score  false 1 score  precision score  recall score\n",
      "0          0.5825       0.616092         0.463668      0.917808\n",
      "1          0.5560       0.617900         0.455584      0.959893\n",
      "2          0.4975       0.572522         0.412125      0.937326\n",
      "3          0.4935       0.575262         0.412756      0.948824\n",
      "mean accuracy score: 0.532375 \n",
      "mean false 1 score: 0.5954441278925943 \n",
      "mean precision score: 0.4360330539682403 \n",
      "mean recall score: 0.9409628789035294\n"
     ]
    }
   ],
   "source": [
    "cv(5,SVC(kernel='poly',degree=1,max_iter=1000),X,y,wvs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Zhu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Zhu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Zhu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy score  false 1 score  precision score  recall score\n",
      "0          0.3650       0.534799           0.3650           1.0\n",
      "1          0.3740       0.544396           0.3740           1.0\n",
      "2          0.3590       0.528330           0.3590           1.0\n",
      "3          0.3615       0.531032           0.3615           1.0\n",
      "mean accuracy score: 0.36487499999999995 \n",
      "mean false 1 score: 0.5346390158299195 \n",
      "mean precision score: 0.36487499999999995 \n",
      "mean recall score: 1.0\n"
     ]
    }
   ],
   "source": [
    "cv(5,SVC(kernel='sigmoid',gamma=0.8,max_iter=1000),X,y,wvs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Zhu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Zhu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Zhu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy score  false 1 score  precision score  recall score\n",
      "0           0.510       0.580479         0.422167      0.928767\n",
      "1           0.507       0.580426         0.425718      0.911765\n",
      "2           0.494       0.570458         0.410256      0.935933\n",
      "3           0.488       0.562767         0.407041      0.911480\n",
      "mean accuracy score: 0.49974999999999997 \n",
      "mean false 1 score: 0.5735325634927373 \n",
      "mean precision score: 0.41629563018308224 \n",
      "mean recall score: 0.9219862303693254\n"
     ]
    }
   ],
   "source": [
    "cv(5,SVC(kernel='rbf',gamma=1,max_iter=1000),X,y,wvs_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (2pt) If your models worked like mine, you may have noticed that while accuracy seems all right,\n",
    "precision and recall are rather low. Explain what does such a phenomenon mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the participant made postive choices upon this question.A situation of Low Precision emerges when very few of your positive predictions are true, and Low Recall occurs if most of your positive values are never predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the models (3pt)\n",
    "1. (2pt) Finally, compare the models. Which ones performed the best in terms of accuracy? Which\n",
    "ones in terms of F-score? Did you encounter other kind of issues with certain models? Which models\n",
    "were fast and which ones slow?\n",
    "2. (1pt) If you have to repeat the exercise with a single model (and you have, see below), which one\n",
    "will you pick?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By using 10000 samples from the original dataset, logistic regression is the best in terms of both accuracy and F-score. I changed the number of my samples during the process and I found that the best models are different. Sometimes the best model is the kNN model in different k. SVM is snow and logistic regression is the fastest.  \n",
    "* I would choose the kNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How large a role does country play? (20pt)\n",
    "Here we switch from machine learning to social sciences. Public opinion differs from country to country,\n",
    "but also inside the countries. Does the fact that we include country code in data help us to substantially\n",
    "improve the predictions?\n",
    "You pick the best ML method from above. You estimate two sets of models: one with country\n",
    "information included, and one where it is removed. Is the former noticeably better than the latter?\n",
    "1. (10pt) Pick your best ML method based you designed above. Cross-validate the accuracy of abortion\n",
    "variable using all the features, including country dummies and report the accuracy. Essentially you\n",
    "repeat here what you did above, so you can also just copy the result from above.\n",
    "2. (15pt) Now remove all the country dummies, but keep the other variables intact. And repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=wvs2.V204\n",
    "X=wvs2.drop('V204',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy score  false 1 score  precision score  recall score\n",
      "0        0.837139       0.766038         0.799206      0.735514\n",
      "1        0.834101       0.764210         0.794853      0.735843\n",
      "2        0.836939       0.763646         0.799540      0.730837\n",
      "3        0.831830       0.760725         0.794973      0.729306\n",
      "mean accuracy score: 0.835002252903356 \n",
      "mean false 1 score: 0.763655022662412 \n",
      "mean precision score: 0.7971429651300777 \n",
      "mean recall score: 0.7328749380678234\n"
     ]
    }
   ],
   "source": [
    "cv(5,LogisticRegression(solver='liblinear', random_state=0),X,y,wvs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_new=wvs.drop(['country'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy score  false 1 score  precision score  recall score\n",
      "0        0.834174       0.760761         0.797406      0.727336\n",
      "1        0.832839       0.761990         0.794085      0.732390\n",
      "2        0.831767       0.756772         0.790135      0.726111\n",
      "3        0.828991       0.756402         0.791463      0.724316\n",
      "mean accuracy score: 0.8319429418037461 \n",
      "mean false 1 score: 0.7589811997601386 \n",
      "mean precision score: 0.7932720878091655 \n",
      "mean recall score: 0.727538190555903\n"
     ]
    }
   ],
   "source": [
    "y=wvs_new.V204\n",
    "X=wvs_new.drop('V204',1)\n",
    "cv(5,LogisticRegression(solver='liblinear', random_state=0),X,y,wvs_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (5pt) Comment what you found. Does country information help to noticeably improve the prediction?  \n",
    "**The sample of the original data shows a accuracy score of about 0.82. The data without any country or country dummies has an accuracy score of 0.8319, higher than the former one. And the data including dummies is the highest between the three all. So the country information helps to improve the prediction and the country variable should better be dummied.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
