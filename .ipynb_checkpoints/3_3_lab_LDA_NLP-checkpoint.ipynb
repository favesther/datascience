{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "import pyLDAvis\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hopes</th>\n",
       "      <th>Fears</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get a good data science project that I can put...</td>\n",
       "      <td>Not being able to be productive due to online ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That I get to learn advanced concepts of big d...</td>\n",
       "      <td>That I come from a background of R programming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am able to master deep learning techniques</td>\n",
       "      <td>That I do not possess the necessary skillset r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have had a good background  in statistics, d...</td>\n",
       "      <td>My biggest fear is the time is not enough to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Take away solid skills and technologies which ...</td>\n",
       "      <td>A project which isn't relevant or impactful, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Hopes  \\\n",
       "0  Get a good data science project that I can put...   \n",
       "1  That I get to learn advanced concepts of big d...   \n",
       "2       I am able to master deep learning techniques   \n",
       "3  I have had a good background  in statistics, d...   \n",
       "4  Take away solid skills and technologies which ...   \n",
       "\n",
       "                                               Fears  \n",
       "0  Not being able to be productive due to online ...  \n",
       "1  That I come from a background of R programming...  \n",
       "2  That I do not possess the necessary skillset r...  \n",
       "3  My biggest fear is the time is not enough to l...  \n",
       "4  A project which isn't relevant or impactful, a...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataIn = pd.read_csv('hopesAndFearsShort.csv')\n",
    "dataIn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataIn.Hopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything to lower case\n",
    "data=data.str.lower()\n",
    "# replace lines and tabs\n",
    "data=data.str.replace('\\n',' ')\n",
    "data=data.str.replace('\\t',' ')\n",
    "#regularize all the characters\n",
    "data=data.str.replace(r\"[^\\w\\s']\",' ')\n",
    "data=data.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring in stop words\n",
    "stops=stopwords.words('english')\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend([\"i'd\",'yet','via','also','along','way'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'main goal class hone data scienc skill appli solv real world problem hope achiev work fun meaning project group hope showcas data scienc chop potenti employ group project like pick new skill'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemmer eliminates different conditions of one word\n",
    "# join put the splitted words into one string\n",
    "' '.join([stemmer.stem(word) for word in x.split() if word not in stops])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one line function lambda to apply above\n",
    "data=data.apply(lambda x:' '.join([stemmer.stem(word) for word in x.split() if word not in stops]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                get good data scienc project put resum\n",
       "1     get learn advanc concept big data complet data...\n",
       "2                        abl master deep learn techniqu\n",
       "3     good background statist data analysi machin le...\n",
       "4     take away solid skill technolog give improv em...\n",
       "5     understand well enough abl explain interview w...\n",
       "6     know method follow solv real world big data pr...\n",
       "7     biggest hope would learn neural network realli...\n",
       "8     accomplish real project first experi data scie...\n",
       "9     hope big learn curv whole data pipelin opportu...\n",
       "10    main goal class hone data scienc skill appli s...\n",
       "11    biggest hope learn work unstructur data hope g...\n",
       "12    would help learn variou technolog handl huge a...\n",
       "13    biggest hope cours learn data scienc techniqu ...\n",
       "14    enhanc skill understand import machin learn co...\n",
       "15    answer data scienc question end end test well ...\n",
       "16    complet project proud well becom prepar futur ...\n",
       "17    hope i'm abl contribut project i'm proud showc...\n",
       "18    learn new concept work cloud base platform lar...\n",
       "19    wish dive deeper realm nlp big data neural net...\n",
       "20    learn concept would realli relev industri woul...\n",
       "21    hope dug deeper data scienc understand domain ...\n",
       "22    get exposur real world problem new technolog m...\n",
       "23    biggest hope touch real world larger data play...\n",
       "24    hope class good culmin data scienc special tie...\n",
       "25    1 revisit concept touch base imt573 imt574 2 r...\n",
       "26    biggest hope imt 575 enough experi data scienc...\n",
       "27    biggest hope imt 575 comfort deal sort type da...\n",
       "28                        learn analyz differ type data\n",
       "29    biggest hope imt 575 learn neural network natu...\n",
       "30    gain refin skill technic peopl project manag s...\n",
       "31    first two quarter data scienc special help dev...\n",
       "Name: Hopes, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.fit(data)\n",
    "counts=vec.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 273)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdfVec=TfidfVectorizer()\n",
    "tfIdf=tfIdfVec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdf=pd.DataFrame(tfIdf.toarray(),columns=tfIdfVec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.2810494032626764)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find \"data science\"\n",
    "counts.iloc[10]['skill'],tfIdf.iloc[10]['skill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.1452799381655528)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.iloc[10]['data'],tfIdf.iloc[10]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.21283769753750711)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.iloc[10]['scienc'],tfIdf.iloc[10]['scienc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "although the words appear the same times in a document, their frequencies are different in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda=LDA(n_components=3, random_state=11)\n",
    "lda.fit(counts)\n",
    "ldaOut=lda.transform(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaOut.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn\n",
    "counts=vec.transform(data)\n",
    "p=pyLDAvis.sklearn.prepare(lda, counts, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(p,'Hopes.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataIn.Fears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything to lower case\n",
    "data=data.str.lower()\n",
    "# replace lines and tabs\n",
    "data=data.str.replace('\\n',' ')\n",
    "data=data.str.replace('\\t',' ')\n",
    "#regularize all the characters\n",
    "data=data.str.replace(r\"[^\\w\\s']\",' ')\n",
    "data=data.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring in stop words\n",
    "stops=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the three different stemmer\n",
    "stemmerPort=PorterStemmer()\n",
    "stemmerSnow=EnglishStemmer()\n",
    "stemmerLanc=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend([\"i'll\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one line function lambda to apply above\n",
    "data=data.apply(lambda x:' '.join([stemmer.stem(word) for word in x.split() if word not in stops]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=CountVectorizer()\n",
    "vec.fit(data)\n",
    "counts=vec.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 320)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdfVec=TfidfVectorizer()\n",
    "tfIdf=tfIdfVec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdf=pd.DataFrame(tfIdf.toarray(),columns=tfIdfVec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'biggest fear imt 575 lectur onlin due covid 19 pandem gener ds assign time consum intens imt 574 winter 2020 hope attend lectur remot enough us solv assign abl avail equal time attent effort cours spring quarter'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.1438704231463137)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.iloc[10]['internship'],tfIdf.iloc[10]['internship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.1755100196111007)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.iloc[29]['project'],tfIdf.iloc[29]['project']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.29388328711423456)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.iloc[29]['final'],tfIdf.iloc[29]['final']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "although the words appear the same times in a document, their frequencies are different in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda=LDA(n_components=3, random_state=11)\n",
    "lda.fit(counts)\n",
    "ldaOut=lda.transform(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=vec.transform(data)\n",
    "p=pyLDAvis.sklearn.prepare(lda, counts, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(p,'Fears.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts=pd.read_csv('abstracts2.txt',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pID</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4618374</td>\n",
       "      <td>The article addresses Vera's unusual foregroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1609906</td>\n",
       "      <td>Spermatocytes of the crane-fly,Nephrotoma sutu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2983758</td>\n",
       "      <td>The problem of estimating distance to a stella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4397894</td>\n",
       "      <td>The article is based on a study aimed to under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1731317</td>\n",
       "      <td>Brains of rats undernourished from midgestatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1129316</td>\n",
       "      <td>By using behavioral observations and sociometr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1612345</td>\n",
       "      <td>Cells with polyploid nuclei are generally larg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>20063747</td>\n",
       "      <td>Old-growth bottomland hardwood-Pinus taeda L. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3088351</td>\n",
       "      <td>In my original study, \"Long-Run Convergence of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>4092389</td>\n",
       "      <td>Scholars often use roll-call votes to study le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pID                                           abstract\n",
       "0      4618374  The article addresses Vera's unusual foregroun...\n",
       "1      1609906  Spermatocytes of the crane-fly,Nephrotoma sutu...\n",
       "2      2983758  The problem of estimating distance to a stella...\n",
       "3      4397894  The article is based on a study aimed to under...\n",
       "4      1731317  Brains of rats undernourished from midgestatio...\n",
       "...        ...                                                ...\n",
       "9995   1129316  By using behavioral observations and sociometr...\n",
       "9996   1612345  Cells with polyploid nuclei are generally larg...\n",
       "9997  20063747  Old-growth bottomland hardwood-Pinus taeda L. ...\n",
       "9998   3088351  In my original study, \"Long-Run Convergence of...\n",
       "9999   4092389  Scholars often use roll-call votes to study le...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       articl address vera' unusu foreground violent ...\n",
       "1       spermatocyt crane fli nephrotoma suturali atta...\n",
       "2       problem estim distanc stellar system measur ap...\n",
       "3       articl base studi aim understand analys tenanc...\n",
       "4       brain rat undernourish midgest kill wean conta...\n",
       "                              ...                        \n",
       "9995    use behavior observ sociometr method stabl dom...\n",
       "9996    cell polyploid nuclei gener larger cell organ ...\n",
       "9997    old growth bottomland hardwood pinu taeda l fo...\n",
       "9998    origin studi long run converg ethnic skill dif...\n",
       "9999    scholar often use roll call vote studi legisl ...\n",
       "Name: abstract, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=abstracts.abstract\n",
    "# put everything to lower case\n",
    "data=data.str.lower()\n",
    "# replace lines and tabs\n",
    "data=data.str.replace('\\n',' ')\n",
    "data=data.str.replace('\\t',' ')\n",
    "#regularize all the characters\n",
    "data=data.str.replace(r\"[^\\w\\s']\",' ')\n",
    "data=data.str.strip()\n",
    "#bring in stop words\n",
    "stops=stopwords.words('english')\n",
    "stemmer=PorterStemmer()\n",
    "data=data.apply(lambda x:' '.join([stemmer.stem(word) for word in x.split() if word not in stops]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=CountVectorizer()\n",
    "vec.fit(data)\n",
    "counts=vec.transform(data)\n",
    "counts=counts.toarray()\n",
    "counts=pd.DataFrame(counts,columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdfVec=TfidfVectorizer()\n",
    "tfIdf=tfIdfVec.fit_transform(data)\n",
    "tfIdf=pd.DataFrame(tfIdf.toarray(),columns=tfIdfVec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"two laboratori experi investig mate guard sperm alloc pattern adult male virgin femal snow crab chionoecet opilio relat sex ratio although femal outnumb male treatment oper sex ratio male bias femal matur asynchron limit period sexual attract matur molt male guard femal significantli longer sex ratio increas mean time per femal 2 9 2 20 treatment compar 5 6 6 20 treatment femal injuri mortal scale posit sex ratio male guard greatest number day significantli larger experiment' end significantli smaller vasa deferentia suggest greater sperm expens male guard fewer day experi spermathec load sl quantiti ejacul store female' spermatheca independ molt date except femal bias treatment neg relat sl increas sex ratio increas mainli femal accumul ejacul howev similarli size male smaller vasa deferentia pass smaller ejacul given sex ratio mean sl 55 less one experi femal extrud clutch fertil egg median sl 3 4 mg one order magnitud smaller femal well fertil clutch 31 50 mg indic sperm limit male econom sperm femal irrespect sex ratio insemin vari extent submaxim ejacul repres less 2 5 male sperm reserv male fulli exhaust sperm sperm economi predict sperm competit theori speci like snow crab polyandri exist mechan last male sperm preced effect probabl one male fertil female' lifetim product egg small\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 0.3222182601512589)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.iloc[200]['femal'],tfIdf.iloc[200]['femal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 0.4324161584591311)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.iloc[200]['sperm'],tfIdf.iloc[200]['sperm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda=LDA(n_components=16, random_state=0)\n",
    "lda.fit(counts)\n",
    "ldaOut=lda.transform(counts)\n",
    "p=pyLDAvis.sklearn.prepare(lda, counts, vec)\n",
    "pyLDAvis.save_html(p,'Abstract.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
